{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92025c43",
   "metadata": {},
   "source": [
    "# üîß Proje 1: Hiperparametre Optimizasyonu\n",
    "\n",
    "**Ders:** Optimizasyon Algoritmalarƒ±  \n",
    "**Veri Seti:** √áelik Levha Hata Tespiti  \n",
    "**Ama√ß:** Grid Search, Random Search ve Bayesian Optimizasyonu kar≈üƒ±la≈ütƒ±rmak\n",
    "\n",
    "---\n",
    "\n",
    "## ƒ∞√ßindekiler\n",
    "1. Giri≈ü\n",
    "2. Kurulum ve ƒ∞√ße Aktarma\n",
    "3. Veri Y√ºkleme\n",
    "4. Veri Ke≈üfi\n",
    "5. √ñn ƒ∞≈üleme\n",
    "6. Grid Search\n",
    "7. Random Search\n",
    "8. Bayesian Optimizasyon\n",
    "9. Sonu√ß Kar≈üƒ±la≈ütƒ±rmasƒ±\n",
    "10. Sonu√ßlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8441a2",
   "metadata": {},
   "source": [
    "## 2. Kurulum ve ƒ∞√ße Aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.samplers import TPESampler\n",
    "    OPTUNA_AVAILABLE = True\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Libraries imported!\" + (\" Optuna: ‚úÖ\" if OPTUNA_AVAILABLE else \" Optuna: ‚ùå\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b747e",
   "metadata": {},
   "source": [
    "## 3. Veri Y√ºkleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "feature_names = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "    'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity',\n",
    "    'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300',\n",
    "    'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index',\n",
    "    'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index',\n",
    "    'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index',\n",
    "    'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas']\n",
    "class_names = ['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/raw/steel_plates_fault.csv', header=None)\n",
    "df.columns = feature_names + class_names\n",
    "print(f\"‚úÖ Loaded: {df.shape[0]} samples, {len(feature_names)} features, {len(class_names)} classes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be5697",
   "metadata": {},
   "source": [
    "## 4. Veri Ke≈üfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "y_labels = df[class_names].idxmax(axis=1)\n",
    "print(\"üìä Class Distribution:\")\n",
    "for cls in class_names:\n",
    "    count = (y_labels == cls).sum()\n",
    "    print(f\"  {cls:15}: {count:4} ({count/len(y_labels)*100:.1f}%)\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "y_labels.value_counts().plot(kind='bar', color=plt.cm.viridis(np.linspace(0.2, 0.8, 7)), ax=ax)\n",
    "ax.set_title('Class Distribution', fontweight='bold')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e03339",
   "metadata": {},
   "source": [
    "## 5. √ñn ƒ∞≈üleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df[feature_names].values\n",
    "y = df[class_names].values.argmax(axis=1)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e8fb3",
   "metadata": {},
   "source": [
    "## 6. Grid Search\n",
    "\n",
    "T√ºm parametre kombinasyonlarƒ±nƒ± kapsamlƒ± olarak deƒüerlendirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'SVM': {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']},\n",
    "    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [10, 15], 'min_samples_split': [2, 5]},\n",
    "    'NeuralNetwork': {'hidden_layer_sizes': [(50,), (100,)], 'alpha': [0.001, 0.01]}\n",
    "}\n",
    "\n",
    "def grid_search(name):\n",
    "    print(f\"\\nüîç Grid Search: {name}\")\n",
    "    model = {'SVM': SVC(random_state=42), 'RandomForest': RandomForestClassifier(random_state=42),\n",
    "             'NeuralNetwork': MLPClassifier(random_state=42, max_iter=500)}[name]\n",
    "    start = time.time()\n",
    "    gs = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    gs.fit(X_train_scaled, y_train)\n",
    "    t = time.time() - start\n",
    "    print(f\"  ‚è±Ô∏è {t:.1f}s | üéØ {gs.best_score_:.4f} | {gs.best_params_}\")\n",
    "    return {'model': name, 'method': 'Grid', 'score': gs.best_score_, 'time': t, 'est': gs.best_estimator_}\n",
    "\n",
    "grid_results = [grid_search(m) for m in ['SVM', 'RandomForest', 'NeuralNetwork']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca1a73",
   "metadata": {},
   "source": [
    "## 7. Random Search\n",
    "\n",
    "Rastgele parametre kombinasyonlarƒ± √∂rnekler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distributions\n",
    "param_dists = {\n",
    "    'SVM': {'C': uniform(0.1, 50), 'gamma': ['scale', 'auto'], 'kernel': ['rbf', 'poly']},\n",
    "    'RandomForest': {'n_estimators': randint(50, 200), 'max_depth': randint(5, 20), 'min_samples_split': randint(2, 10)},\n",
    "    'NeuralNetwork': {'hidden_layer_sizes': [(50,), (100,), (100, 50)], 'alpha': uniform(0.0001, 0.01)}\n",
    "}\n",
    "\n",
    "def random_search(name, n_iter=20):\n",
    "    print(f\"\\nüé≤ Random Search: {name}\")\n",
    "    model = {'SVM': SVC(random_state=42), 'RandomForest': RandomForestClassifier(random_state=42),\n",
    "             'NeuralNetwork': MLPClassifier(random_state=42, max_iter=500)}[name]\n",
    "    start = time.time()\n",
    "    rs = RandomizedSearchCV(model, param_dists[name], n_iter=n_iter, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "    rs.fit(X_train_scaled, y_train)\n",
    "    t = time.time() - start\n",
    "    print(f\"  ‚è±Ô∏è {t:.1f}s | üéØ {rs.best_score_:.4f} | {rs.best_params_}\")\n",
    "    return {'model': name, 'method': 'Random', 'score': rs.best_score_, 'time': t, 'est': rs.best_estimator_}\n",
    "\n",
    "random_results = [random_search(m) for m in ['SVM', 'RandomForest', 'NeuralNetwork']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf93b5b",
   "metadata": {},
   "source": [
    "## 8. Bayesian Optimizasyon (Optuna)\n",
    "\n",
    "Aramayƒ± akƒ±llƒ±ca y√∂nlendirmek i√ßin olasƒ±lƒ±ksal model kullanƒ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22be397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_opt(name, n_trials=20):\n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print(f\"‚ö†Ô∏è Optuna not available\")\n",
    "        return None\n",
    "    print(f\"\\nüß† Bayesian: {name}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        if name == 'SVM':\n",
    "            p = {'C': trial.suggest_float('C', 0.1, 50, log=True), 'gamma': trial.suggest_categorical('gamma', ['scale', 'auto'])}\n",
    "            m = SVC(**p, random_state=42)\n",
    "        elif name == 'RandomForest':\n",
    "            p = {'n_estimators': trial.suggest_int('n_estimators', 50, 200), \n",
    "                 'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "                 'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)}\n",
    "            m = RandomForestClassifier(**p, random_state=42)\n",
    "        else:\n",
    "            p = {'hidden_layer_sizes': trial.suggest_categorical('h', [(50,), (100,)]), 'alpha': trial.suggest_float('alpha', 0.0001, 0.01, log=True)}\n",
    "            m = MLPClassifier(**p, random_state=42, max_iter=500)\n",
    "        return cross_val_score(m, X_train_scaled, y_train, cv=5).mean()\n",
    "    \n",
    "    start = time.time()\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    t = time.time() - start\n",
    "    print(f\"  ‚è±Ô∏è {t:.1f}s | üéØ {study.best_value:.4f} | {study.best_params}\")\n",
    "    return {'model': name, 'method': 'Bayesian', 'score': study.best_value, 'time': t}\n",
    "\n",
    "bayesian_results = [r for r in [bayesian_opt(m) for m in ['SVM', 'RandomForest', 'NeuralNetwork']] if r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fad62",
   "metadata": {},
   "source": [
    "## 9. Sonu√ß Kar≈üƒ±la≈ütƒ±rmasƒ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad878a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results\n",
    "all_results = grid_results + random_results + bayesian_results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"üìä All Results:\")\n",
    "display(results_df[['model', 'method', 'score', 'time']].round(4))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "pivot = results_df.pivot(index='model', columns='method', values='score')\n",
    "pivot.plot(kind='bar', ax=axes[0], colormap='viridis', edgecolor='black')\n",
    "axes[0].set_title('Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend(title='Method')\n",
    "\n",
    "pivot_time = results_df.pivot(index='model', columns='method', values='time')\n",
    "pivot_time.plot(kind='bar', ax=axes[1], colormap='plasma', edgecolor='black')\n",
    "axes[1].set_title('Time Comparison', fontweight='bold')\n",
    "axes[1].set_ylabel('Time (s)')\n",
    "axes[1].legend(title='Method')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Best\n",
    "best = results_df.loc[results_df['score'].idxmax()]\n",
    "print(f\"\\nüèÜ Best: {best['model']} with {best['method']} ({best['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcf71a",
   "metadata": {},
   "source": [
    "## 10. Sonu√ßlar\n",
    "\n",
    "### üéØ Temel Bulgular\n",
    "\n",
    "| Y√∂ntem | Avantajlar | En ƒ∞yi Kullanƒ±m |\n",
    "|--------|------------|-----------------|\n",
    "| **Bayesian** | En verimli, ge√ßmi≈üten √∂ƒürenir | √úretim |\n",
    "| **Random Search** | Hƒ±zlƒ±, iyi ke≈üif | Prototipleme |\n",
    "| **Grid Search** | Garantili kapsam | K√º√ß√ºk alanlar |\n",
    "\n",
    "### üìå √ñneriler\n",
    "1. Pahalƒ± deƒüerlendirmeler i√ßin **Bayesian Optimizasyon** kullanƒ±n\n",
    "2. Hƒ±zlƒ± ba≈ülangƒ±√ßlar i√ßin **Random Search** kullanƒ±n\n",
    "3. Son ayarlama i√ßin **Grid Search** kullanƒ±n\n",
    "\n",
    "‚úÖ **Proje tamamlandƒ±!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
